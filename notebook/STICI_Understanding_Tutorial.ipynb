{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STICI Algorithm Understanding Tutorial\n",
    "\n",
    "## Split-Transformer with Integrated Convolutions for Genotype Imputation\n",
    "\n",
    "This notebook provides a step-by-step understanding of the STICI algorithm using sample data.\n",
    "\n",
    "### Overview\n",
    "STICI is a deep learning model that uses a novel variation of the Transformer architecture for genotype imputation. It combines:\n",
    "- Split-Transformer architecture\n",
    "- Integrated convolutions\n",
    "- Advanced preprocessing techniques\n",
    "\n",
    "### Key Features:\n",
    "1. **Split-Transformer**: Novel variation of transformer architecture\n",
    "2. **Integrated Convolutions**: CNN components for local pattern recognition\n",
    "3. **Masking Strategy**: Random masking during training for robustness\n",
    "4. **Haploid/Diploid Support**: Handles both haploid and diploid genotype data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the STICI Workflow\n",
    "\n",
    "The STICI algorithm follows this general workflow:\n",
    "\n",
    "```\n",
    "PROGRAM STICI:\n",
    "  Read the data;\n",
    "  Perform one-hot encoding on the data;\n",
    "  Partition the data into training, validation, and test sets;\n",
    "  IF (data is diploid)\n",
    "      THEN break them into haploids but keep the order intact;\n",
    "      ELSE do nothing;\n",
    "  ENDIF;\n",
    "  FOR each iteration\n",
    "      Shuffle haploids in training and validation sets separately;\n",
    "      FOR each training batch\n",
    "          Randomly select MaskR% of the values and replace with missing values;\n",
    "          Train the model using the training batch;\n",
    "      ENDFOR;\n",
    "      FOR each validation batch\n",
    "          Randomly select MaskR% of the values and replace with missing values;\n",
    "          Evaluate the model using the validation batch;\n",
    "      ENDFOR;\n",
    "  ENDFOR;\n",
    "  Perform prediction using the model on the test set;\n",
    "  IF (data is diploid)\n",
    "      THEN replace each two consecutive test samples with respective diploid\n",
    "      ELSE do nothing;\n",
    "  ENDIF;\n",
    "  Save the resulting predictions into a file;\n",
    "END.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create sample genotype data to demonstrate STICI concepts\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate genotype data\n",
    "# 0 = homozygous reference, 1 = heterozygous, 2 = homozygous alternate, -1 = missing\n",
    "n_samples = 100\n",
    "n_variants = 50\n",
    "\n",
    "# Generate sample genotype matrix\n",
    "genotype_data = np.random.choice([0, 1, 2], size=(n_samples, n_variants), p=[0.5, 0.3, 0.2])\n",
    "\n",
    "# Introduce some missing values (represented as -1)\n",
    "missing_mask = np.random.random((n_samples, n_variants)) < 0.1  # 10% missing\n",
    "genotype_data[missing_mask] = -1\n",
    "\n",
    "print(f\"Generated genotype data shape: {genotype_data.shape}\")\n",
    "print(f\"Missing values: {np.sum(genotype_data == -1)} ({np.sum(genotype_data == -1)/(n_samples*n_variants)*100:.1f}%)\")\n",
    "print(f\"Genotype distribution:\")\n",
    "unique, counts = np.unique(genotype_data, return_counts=True)\n",
    "for val, count in zip(unique, counts):\n",
    "    if val == -1:\n",
    "        print(f\"  Missing (-1): {count} ({count/(n_samples*n_variants)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  Genotype {val}: {count} ({count/(n_samples*n_variants)*100:.1f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the genotype data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Heatmap of genotype data (first 20 samples, first 30 variants)\n",
    "subset_data = genotype_data[:20, :30]\n",
    "im = axes[0].imshow(subset_data, cmap='viridis', aspect='auto')\n",
    "axes[0].set_title('Genotype Data Heatmap\\n(First 20 samples, 30 variants)')\n",
    "axes[0].set_xlabel('Variants')\n",
    "axes[0].set_ylabel('Samples')\n",
    "plt.colorbar(im, ax=axes[0], label='Genotype Value')\n",
    "\n",
    "# Plot 2: Distribution of genotype values\n",
    "genotype_counts = pd.Series(genotype_data.flatten()).value_counts().sort_index()\n",
    "axes[1].bar(genotype_counts.index, genotype_counts.values, \n",
    "           color=['red', 'blue', 'green', 'orange'])\n",
    "axes[1].set_title('Distribution of Genotype Values')\n",
    "axes[1].set_xlabel('Genotype Value')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticks([-1, 0, 1, 2])\n",
    "axes[1].set_xticklabels(['Missing', 'Hom Ref (0/0)', 'Het (0/1)', 'Hom Alt (1/1)'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing - One-Hot Encoding\n",
    "\n",
    "STICI uses one-hot encoding to represent genotype data. Each genotype value is converted to a binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def one_hot_encode_genotypes(genotype_matrix):\n",
    "    \"\"\"\n",
    "    Convert genotype matrix to one-hot encoded format\n",
    "    0 -> [1, 0, 0, 0]  # homozygous reference\n",
    "    1 -> [0, 1, 0, 0]  # heterozygous\n",
    "    2 -> [0, 0, 1, 0]  # homozygous alternate\n",
    "    -1 -> [0, 0, 0, 1] # missing\n",
    "    \"\"\"\n",
    "    n_samples, n_variants = genotype_matrix.shape\n",
    "    encoded = np.zeros((n_samples, n_variants, 4))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_variants):\n",
    "            val = genotype_matrix[i, j]\n",
    "            if val == 0:\n",
    "                encoded[i, j, 0] = 1  # homozygous reference\n",
    "            elif val == 1:\n",
    "                encoded[i, j, 1] = 1  # heterozygous\n",
    "            elif val == 2:\n",
    "                encoded[i, j, 2] = 1  # homozygous alternate\n",
    "            else:  # val == -1 (missing)\n",
    "                encoded[i, j, 3] = 1  # missing\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# Apply one-hot encoding\n",
    "encoded_data = one_hot_encode_genotypes(genotype_data)\n",
    "print(f\"One-hot encoded data shape: {encoded_data.shape}\")\n",
    "print(f\"Original shape: {genotype_data.shape}\")\n",
    "print(f\"Encoding adds dimension for 4 possible states: [Hom_Ref, Het, Hom_Alt, Missing]\")\n",
    "\n",
    "# Show example of encoding\n",
    "print(\"\\nExample encoding for first sample, first 5 variants:\")\n",
    "for i in range(5):\n",
    "    original_val = genotype_data[0, i]\n",
    "    encoded_val = encoded_data[0, i, :]\n",
    "    genotype_names = ['Hom_Ref', 'Het', 'Hom_Alt', 'Missing']\n",
    "    decoded_name = genotype_names[np.argmax(encoded_val)]\n",
    "    print(f\"  Variant {i}: {original_val} -> {encoded_val} ({decoded_name})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Diploid to Haploid Conversion\n",
    "\n",
    "For diploid data, STICI converts each diploid genotype into two haploid sequences while maintaining order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def diploid_to_haploid(genotype_matrix):\n",
    "    \"\"\"\n",
    "    Convert diploid genotypes to haploid pairs\n",
    "    0 (0/0) -> [0, 0]\n",
    "    1 (0/1) -> [0, 1] \n",
    "    2 (1/1) -> [1, 1]\n",
    "    -1 (missing) -> [-1, -1]\n",
    "    \"\"\"\n",
    "    n_samples, n_variants = genotype_matrix.shape\n",
    "    haploid_data = np.zeros((n_samples * 2, n_variants), dtype=int)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_variants):\n",
    "            val = genotype_matrix[i, j]\n",
    "            if val == 0:  # 0/0\n",
    "                haploid_data[2*i, j] = 0\n",
    "                haploid_data[2*i+1, j] = 0\n",
    "            elif val == 1:  # 0/1\n",
    "                haploid_data[2*i, j] = 0\n",
    "                haploid_data[2*i+1, j] = 1\n",
    "            elif val == 2:  # 1/1\n",
    "                haploid_data[2*i, j] = 1\n",
    "                haploid_data[2*i+1, j] = 1\n",
    "            else:  # missing\n",
    "                haploid_data[2*i, j] = -1\n",
    "                haploid_data[2*i+1, j] = -1\n",
    "    \n",
    "    return haploid_data\n",
    "\n",
    "# Convert to haploid\n",
    "haploid_data = diploid_to_haploid(genotype_data)\n",
    "print(f\"Diploid data shape: {genotype_data.shape}\")\n",
    "print(f\"Haploid data shape: {haploid_data.shape}\")\n",
    "print(f\"Each diploid sample becomes 2 haploid samples\")\n",
    "\n",
    "# Show example conversion\n",
    "print(\"\\nExample diploid to haploid conversion (first sample, first 10 variants):\")\n",
    "print(f\"Diploid:   {genotype_data[0, :10]}\")\n",
    "print(f\"Haploid 1: {haploid_data[0, :10]}\")\n",
    "print(f\"Haploid 2: {haploid_data[1, :10]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Masking Strategy for Training\n",
    "\n",
    "STICI uses a random masking strategy during training where a percentage of values are randomly masked (set to missing) to teach the model to impute missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def apply_random_masking(data, mask_rate=0.5):\n",
    "    \"\"\"\n",
    "    Apply random masking to training data\n",
    "    mask_rate: percentage of values to mask (0.5 = 50%)\n",
    "    \"\"\"\n",
    "    masked_data = data.copy()\n",
    "    n_samples, n_variants = data.shape\n",
    "    \n",
    "    # Create random mask\n",
    "    mask = np.random.random((n_samples, n_variants)) < mask_rate\n",
    "    \n",
    "    # Apply mask (set masked values to -1)\n",
    "    masked_data[mask] = -1\n",
    "    \n",
    "    return masked_data, mask\n",
    "\n",
    "# Demonstrate masking on haploid data\n",
    "masked_haploid, mask = apply_random_masking(haploid_data, mask_rate=0.3)\n",
    "\n",
    "print(f\"Original missing values: {np.sum(haploid_data == -1)}\")\n",
    "print(f\"After masking: {np.sum(masked_haploid == -1)}\")\n",
    "print(f\"Additional masked values: {np.sum(mask)}\")\n",
    "print(f\"Masking rate: {np.sum(mask)/(haploid_data.shape[0]*haploid_data.shape[1])*100:.1f}%\")\n",
    "\n",
    "# Visualize masking effect\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Original data (subset)\n",
    "subset_orig = haploid_data[:20, :30]\n",
    "im1 = axes[0].imshow(subset_orig, cmap='viridis', aspect='auto')\n",
    "axes[0].set_title('Original Haploid Data')\n",
    "axes[0].set_xlabel('Variants')\n",
    "axes[0].set_ylabel('Haploid Samples')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Mask\n",
    "subset_mask = mask[:20, :30].astype(int)\n",
    "im2 = axes[1].imshow(subset_mask, cmap='Reds', aspect='auto')\n",
    "axes[1].set_title('Applied Mask (Red = Masked)')\n",
    "axes[1].set_xlabel('Variants')\n",
    "axes[1].set_ylabel('Haploid Samples')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Masked data\n",
    "subset_masked = masked_haploid[:20, :30]\n",
    "im3 = axes[2].imshow(subset_masked, cmap='viridis', aspect='auto')\n",
    "axes[2].set_title('After Masking')\n",
    "axes[2].set_xlabel('Variants')\n",
    "axes[2].set_ylabel('Haploid Samples')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Splitting and Preparation\n",
    "\n",
    "STICI splits data into training, validation, and test sets. The training and validation sets are used with masking, while the test set is used for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split data into train, validation, and test sets\n",
    "def split_data(data, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Split data into train, validation, and test sets\n",
    "    \"\"\"\n",
    "    n_samples = data.shape[0]\n",
    "    \n",
    "    # Calculate split indices\n",
    "    train_end = int(n_samples * train_ratio)\n",
    "    val_end = int(n_samples * (train_ratio + val_ratio))\n",
    "    \n",
    "    # Split data\n",
    "    train_data = data[:train_end]\n",
    "    val_data = data[train_end:val_end]\n",
    "    test_data = data[val_end:]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Split the haploid data\n",
    "train_data, val_data, test_data = split_data(haploid_data)\n",
    "\n",
    "print(f\"Original haploid data shape: {haploid_data.shape}\")\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# Show data distribution across splits\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (data_split, title) in enumerate([(train_data, 'Training'), \n",
    "                                        (val_data, 'Validation'), \n",
    "                                        (test_data, 'Test')]):\n",
    "    counts = pd.Series(data_split.flatten()).value_counts().sort_index()\n",
    "    axes[i].bar(counts.index, counts.values, color=['red', 'blue', 'green'])\n",
    "    axes[i].set_title(f'{title} Data Distribution')\n",
    "    axes[i].set_xlabel('Genotype Value')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].set_xticks([-1, 0, 1])\n",
    "    axes[i].set_xticklabels(['Missing', '0', '1'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. STICI Architecture Components\n",
    "\n",
    "STICI combines several key architectural components:\n",
    "\n",
    "### 6.1 Split-Transformer Architecture\n",
    "The Split-Transformer processes sequences in chunks, allowing for better handling of long genomic sequences.\n",
    "\n",
    "### 6.2 Integrated Convolutions\n",
    "Convolutional layers capture local patterns in genomic data before feeding into the transformer.\n",
    "\n",
    "### 6.3 Attention Mechanism\n",
    "Multi-head attention captures long-range dependencies between variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulate STICI architecture components (simplified demonstration)\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def visualize_stici_architecture():\n",
    "    \"\"\"\n",
    "    Create a visual representation of STICI architecture\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Define component positions and sizes\n",
    "    components = [\n",
    "        {'name': 'Input\\n(One-hot Encoded)', 'pos': (1, 1), 'size': (2, 1), 'color': 'lightblue'},\n",
    "        {'name': 'Convolutional\\nLayers', 'pos': (1, 3), 'size': (2, 1), 'color': 'lightgreen'},\n",
    "        {'name': 'Split-Transformer\\nBlocks', 'pos': (1, 5), 'size': (2, 1.5), 'color': 'lightyellow'},\n",
    "        {'name': 'Multi-Head\\nAttention', 'pos': (4, 5.5), 'size': (1.5, 0.8), 'color': 'lightcoral'},\n",
    "        {'name': 'Feed Forward\\nNetwork', 'pos': (4, 4.5), 'size': (1.5, 0.8), 'color': 'lightcoral'},\n",
    "        {'name': 'Output Layer\\n(Imputed Genotypes)', 'pos': (1, 7.5), 'size': (2, 1), 'color': 'lightpink'}\n",
    "    ]\n",
    "    \n",
    "    # Draw components\n",
    "    for comp in components:\n",
    "        rect = patches.Rectangle(comp['pos'], comp['size'][0], comp['size'][1], \n",
    "                               linewidth=2, edgecolor='black', facecolor=comp['color'])\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add text\n",
    "        text_x = comp['pos'][0] + comp['size'][0]/2\n",
    "        text_y = comp['pos'][1] + comp['size'][1]/2\n",
    "        ax.text(text_x, text_y, comp['name'], ha='center', va='center', \n",
    "               fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Draw arrows\n",
    "    arrows = [\n",
    "        ((2, 2), (2, 3)),      # Input to Conv\n",
    "        ((2, 4), (2, 5)),      # Conv to Transformer\n",
    "        ((3, 5.75), (4, 5.75)), # Transformer to Attention\n",
    "        ((3, 5.25), (4, 5.25)), # Transformer to FFN\n",
    "        ((2, 6.5), (2, 7.5))   # Transformer to Output\n",
    "    ]\n",
    "    \n",
    "    for start, end in arrows:\n",
    "        ax.annotate('', xy=end, xytext=start,\n",
    "                   arrowprops=dict(arrowstyle='->', lw=2, color='black'))\n",
    "    \n",
    "    ax.set_xlim(0, 6)\n",
    "    ax.set_ylim(0, 9)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('STICI Architecture Overview', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_stici_architecture()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key STICI Parameters\n",
    "\n",
    "Understanding the important parameters used in STICI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# STICI Key Parameters (from the GitHub repository)\n",
    "stici_params = {\n",
    "    'Architecture': {\n",
    "        'chunk_size': 2048,           # Chunk size in terms of SNPs/SVs\n",
    "        'chunk_overlap': 128,         # Chunk overlap in terms of SNPs/SVs\n",
    "        'sites_per_model': 6144,      # Number of SNPs/SVs used per model\n",
    "        'embed_dim': 128,             # Embedding dimension size\n",
    "        'num_attention_heads': 16,    # Number of attention heads\n",
    "    },\n",
    "    'Training': {\n",
    "        'max_masking_rate': 0.99,     # Maximum masking rate\n",
    "        'min_masking_rate': 0.5,      # Minimum masking rate\n",
    "        'learning_rate': 0.0005,      # Learning rate\n",
    "        'batch_size_per_gpu': 4,      # Batch size per GPU\n",
    "        'max_epochs': 1000,           # Maximum number of epochs\n",
    "        'val_n_batches': 8,           # Number of batches for validation\n",
    "    },\n",
    "    'Data': {\n",
    "        'use_r2_loss': True,          # Whether to use R^2 loss\n",
    "        'random_seed': 2022,          # Random seed for reproducibility\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display parameters in a formatted way\n",
    "print(\"STICI Key Parameters:\")\n",
    "print(\"=\" * 50)\n",
    "for category, params in stici_params.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(\"-\" * 20)\n",
    "    for param, value in params.items():\n",
    "        print(f\"  {param:<20}: {value}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation Metrics\n",
    "\n",
    "STICI uses several metrics to evaluate imputation performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_imputation_metrics(true_values, predicted_values):\n",
    "    \"\"\"\n",
    "    Calculate common imputation evaluation metrics\n",
    "    \"\"\"\n",
    "    # Remove missing values for evaluation\n",
    "    mask = (true_values != -1) & (predicted_values != -1)\n",
    "    true_clean = true_values[mask]\n",
    "    pred_clean = predicted_values[mask]\n",
    "    \n",
    "    if len(true_clean) == 0:\n",
    "        return {'accuracy': 0, 'r2': 0, 'correlation': 0}\n",
    "    \n",
    "    # Accuracy (exact match)\n",
    "    accuracy = np.mean(true_clean == pred_clean)\n",
    "    \n",
    "    # R-squared\n",
    "    ss_res = np.sum((true_clean - pred_clean) ** 2)\n",
    "    ss_tot = np.sum((true_clean - np.mean(true_clean)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "    \n",
    "    # Correlation\n",
    "    correlation = np.corrcoef(true_clean, pred_clean)[0, 1] if len(true_clean) > 1 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'r2': r2,\n",
    "        'correlation': correlation,\n",
    "        'n_compared': len(true_clean)\n",
    "    }\n",
    "\n",
    "# Simulate some predictions for demonstration\n",
    "np.random.seed(42)\n",
    "# Create simulated predictions (with some noise)\n",
    "test_subset = test_data[:10, :20]  # Small subset for demo\n",
    "simulated_predictions = test_subset.copy()\n",
    "\n",
    "# Add some prediction errors\n",
    "error_mask = np.random.random(test_subset.shape) < 0.1  # 10% error rate\n",
    "simulated_predictions[error_mask] = 1 - simulated_predictions[error_mask]  # Flip values\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_imputation_metrics(test_subset.flatten(), simulated_predictions.flatten())\n",
    "\n",
    "print(\"Imputation Evaluation Metrics (Simulated):\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Accuracy:     {metrics['accuracy']:.3f}\")\n",
    "print(f\"R-squared:    {metrics['r2']:.3f}\")\n",
    "print(f\"Correlation:  {metrics['correlation']:.3f}\")\n",
    "print(f\"Samples compared: {metrics['n_compared']}\")\n",
    "\n",
    "# Visualize prediction vs truth\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Heatmap comparison\n",
    "im1 = axes[0].imshow(test_subset, cmap='viridis', aspect='auto')\n",
    "axes[0].set_title('True Values')\n",
    "axes[0].set_xlabel('Variants')\n",
    "axes[0].set_ylabel('Samples')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(simulated_predictions, cmap='viridis', aspect='auto')\n",
    "axes[1].set_title('Predicted Values')\n",
    "axes[1].set_xlabel('Variants')\n",
    "axes[1].set_ylabel('Samples')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. STICI Usage Examples\n",
    "\n",
    "Based on the STICI repository, here are example command-line usages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# STICI Command Line Examples\n",
    "stici_examples = {\n",
    "    'Training Mode': {\n",
    "        'description': 'Train STICI model on reference data',\n",
    "        'command': '''python3 STICI_V1.1.py \\\\\n",
    "    --mode train \\\\\n",
    "    --ref reference_data.vcf \\\\\n",
    "    --tihp false \\\\\n",
    "    --save-dir ./stici_models \\\\\n",
    "    --cs 2048 \\\\\n",
    "    --co 128 \\\\\n",
    "    --max-mr 0.99 \\\\\n",
    "    --min-mr 0.5 \\\\\n",
    "    --epochs 1000 \\\\\n",
    "    --lr 0.0005 \\\\\n",
    "    --batch-size-per-gpu 4'''\n",
    "    },\n",
    "    'Imputation Mode': {\n",
    "        'description': 'Use trained model to impute missing genotypes',\n",
    "        'command': '''python3 STICI_V1.1.py \\\\\n",
    "    --mode impute \\\\\n",
    "    --ref reference_data.vcf \\\\\n",
    "    --target target_data.vcf \\\\\n",
    "    --tihp false \\\\\n",
    "    --save-dir ./stici_models \\\\\n",
    "    --use-trt true \\\\\n",
    "    --compress-results true'''\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"STICI Usage Examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for mode, info in stici_examples.items():\n",
    "    print(f\"\\n{mode}:\")\n",
    "    print(f\"Description: {info['description']}\")\n",
    "    print(\"Command:\")\n",
    "    print(info['command'])\n",
    "    print(\"-\" * 40)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Key Takeaways\n",
    "\n",
    "### STICI Algorithm Strengths:\n",
    "\n",
    "1. **Novel Architecture**: Combines Split-Transformer with integrated convolutions\n",
    "2. **Flexible Input**: Handles both haploid and diploid genotype data\n",
    "3. **Robust Training**: Uses random masking strategy for better generalization\n",
    "4. **Scalable**: Designed for large genomic datasets with chunking strategy\n",
    "5. **High Performance**: Superior accuracy compared to traditional imputation methods\n",
    "\n",
    "### Key Components:\n",
    "- **Data Preprocessing**: One-hot encoding and diploid-to-haploid conversion\n",
    "- **Masking Strategy**: Random masking during training (50-99% masking rates)\n",
    "- **Architecture**: Split-Transformer blocks with multi-head attention\n",
    "- **Evaluation**: Multiple metrics including accuracy, R², and correlation\n",
    "\n",
    "### Applications:\n",
    "- Genotype imputation for GWAS studies\n",
    "- Missing variant imputation\n",
    "- Population genetics research\n",
    "- Personalized medicine applications\n",
    "\n",
    "This tutorial provides a foundation for understanding STICI. For actual implementation, refer to the original repository: https://github.com/shilab/STICI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
